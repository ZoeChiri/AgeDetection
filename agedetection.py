# -*- coding: utf-8 -*-
"""AgeDetection.ipynb

Automatically generated by Colab.

## Age Detection Using OpenCV
- Python provides libraries for image and video processing; one of them is OpenCV. We are able to capture videos from our web cams with OpenCV.

src : [Geeks for Geeks OpenCV Video Capture ](https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/?ref=gcse)

- We are using pre-trained models because I don't really have time to reinvent the wheel. They're also easier to use for object detection.

## Step 0. Geeks for Geeks tutorial

- First, I followed along a geeksforgeeks tutorial. When using my own images, the ages weren't accurate.
"""

import cv2
import dlib
import numpy as np
import matplotlib.pyplot as plt

## GEEKS FOR GEEKS CODE:
# Install the necessary package for displaying images in Colab
!pip install google-colab-patches

# Import the necessary module for displaying images in Colab
from google.colab.patches import cv2_imshow

## Reading the image/resizing it
img = cv2.imread('/jenna_ortega.jpg')
img = cv2.resize(img, (720, 640))
frame = img.copy()

# ------------ Model for Age detection!!!!! --------#
age_weights = "/age_deploy.prototxt"
age_config = "/age_net.caffemodel"
age_Net = cv2.dnn.readNet(age_config, age_weights)

# Model bins for the age
ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',
        '(25-32)', '(38-43)', '(48-53)', '(60-100)']
model_mean = (78.4263377603, 87.7689143744, 114.895847746) # provided in their model

# storing the image dimensions
fH = img.shape[0]
fW = img.shape[1]

Boxes = [] # to store the face co-ordinates
mssg = 'Face Detected' # to display on image

# ------------- Model for face detection---------#
face_detector = dlib.get_frontal_face_detector()
# converting to grayscale
img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

# -------------detecting the faces--------------#
faces = face_detector(img_gray)

# If no faces our detected
if not faces:
    mssg = 'No face detected'
    cv2.putText(img, f'{mssg}', (40, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 2, (200), 2)
    # Use cv2_imshow instead of cv2.imshow
    cv2_imshow(img)
    cv2.waitKey(0)

else:
    # --------- Bounding Face ---------#
    for face in faces:
        x = face.left() # extracting the face coordinates
        y = face.top()
        x2 = face.right()
        y2 = face.bottom()

        # rescaling those coordinates for our image
        box = [x, y, x2, y2]
        Boxes.append(box)
        cv2.rectangle(frame, (x, y), (x2, y2),
                    (00, 200, 200), 2)

    for box in Boxes:
        face = frame[box[1]:box[3], box[0]:box[2]]

        # ----- Image preprocessing --------#
        blob = cv2.dnn.blobFromImage(
            face, 1.0, (227, 227), model_mean, swapRB=False)

        # -------Age Prediction---------#
        age_Net.setInput(blob)
        age_preds = age_Net.forward()
        age = ageList[age_preds[0].argmax()]

        cv2.putText(frame, f'{mssg}:{age}', (box[0],
                                            box[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                    (0, 255, 255), 2, cv2.LINE_AA)
        # Use cv2_imshow instead of cv2.imshow it makes an error in colab
        cv2_imshow(frame)
        cv2.waitKey(0)

# This code is modified by Susobhan Akhuli



"""## So the model isn't entirely accurate
Or maybe this is why Jenna Ortega plays a lot of younger roles?
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 1. Editing the code for a real-time feed."""

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      video.style.transform = 'scale(-1, 1)'; //I want to mirror the video because it throws me off so bad when it isn't mirrored
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

# Take a photo using the above function
filename = take_photo()

image = cv2.imread(filename)

# Image
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""## It should capture an image that you take on the screen. It doesn't exactly work for video yet, but I am getting close!"""

def take_age(photo_filename):
    # Load our image
    img = cv2.imread(photo_filename)
    img = cv2.resize(img, (720, 640))
    frame = img.copy()

    # Load age detection model
    age_weights = "/age_deploy.prototxt"
    age_config = "/age_net.caffemodel"
    age_net = cv2.dnn.readNet(age_config, age_weights)

    # Model bins for age
    age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',
                '(25-32)', '(38-43)', '(48-53)', '(60-100)']
    model_mean = (78.4263377603, 87.7689143744, 114.895847746)

    # Initialize face detector
    face_detector = dlib.get_frontal_face_detector()
    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces
    faces = face_detector(img_gray)

    if not faces:
        mssg = 'No face detected'
        cv2.putText(img, f'{mssg}', (40, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 2, (200), 2)
        cv2_imshow(img)
        return

    # Process each detected face
    for face in faces:
        x = face.left()
        y = face.top()
        x2 = face.right()
        y2 = face.bottom()

        cv2.rectangle(frame, (x, y), (x2, y2), (0, 200, 200), 2)

        face_img = frame[y:y2, x:x2]
        blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), model_mean, swapRB=False)

        # Age prediction
        age_net.setInput(blob)
        age_preds = age_net.forward()
        age = age_list[age_preds[0].argmax()]

        cv2.putText(frame, f'Face Detected: {age}', (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)

    # Display the resulting frame
    cv2_imshow(frame)

# Example of using the function
photo_filename = take_photo()
take_age(photo_filename)

"""## The model should work when taking your own images now
I think narrowing down the bins should be our next step, and using a better model.

## 2. Using a different model.
"""



"""## 3. Making my own model."""



"""##4. (BONUS!) Adding another model."""

